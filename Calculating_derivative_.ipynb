{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+SRT3uURNErjvbs+QB7lj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaansh81001/Pytorch-IBM-/blob/main/Calculating_derivative_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Derivative in pytorch"
      ],
      "metadata": {
        "id": "MAcdvdA0FHrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "K_4rDI9tFh0Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 here is the value of x that we want to cal the derivative for , requires grad tells pytorch that we will use this value to calc derivatives and gradients"
      ],
      "metadata": {
        "id": "lGgCpaAeFxyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using to calc y(x) = x<sup>2</sup>"
      ],
      "metadata": {
        "id": "IXXfr4oHGMp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0,requires_grad=True)\n",
        "y = x**2"
      ],
      "metadata": {
        "id": "0QIJd-19GMKn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "backward function puts the value of 2 inside the x<sup>2</sup>"
      ],
      "metadata": {
        "id": "ob5bYsM5Gp0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "print(y.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gjPIJ0SJLyM",
        "outputId": "1d80db9b-1e38-4c3b-9b33-bb5aa49d55e4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad function caluclates the derivative"
      ],
      "metadata": {
        "id": "oq2a0b7MGxir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNGhWQEOJN8q",
        "outputId": "7c2ffbcd-c72a-405f-a4da-b1f2b2940451"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "example"
      ],
      "metadata": {
        "id": "L0xBnNu8Jp-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0,requires_grad=True)"
      ],
      "metadata": {
        "id": "ZWODigllKCk6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = x**2 + 2*x + 1\n",
        "z.backward()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45wh611PJohU",
        "outputId": "546f33cc-c17e-4bf0-ebbf-d58bc8ced7bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_ON1iHfJ8xl",
        "outputId": "b9b7bb94-1eb6-402a-c4c1-abf9c2d4c9a7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partial Derivatives"
      ],
      "metadata": {
        "id": "AktTnTeKKPei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = torch.tensor(3.0,requires_grad=True)\n",
        "v = torch.tensor(2.0,requires_grad=True)"
      ],
      "metadata": {
        "id": "35xryo_hKSOL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = u*v+u**2"
      ],
      "metadata": {
        "id": "AfTdDdvcKqJE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.backward()\n",
        "f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liFwEWd8KvLy",
        "outputId": "92ad63ce-8745-47a7-fa45-af8f93ce0877"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGgg74wIK6ZW",
        "outputId": "617affa3-b06f-430a-c00b-66ce41ab6e49"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EukmLy_5K8qW",
        "outputId": "e01c1035-a939-44bf-95bc-faf5c9195b07"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(u.data)   #raw data about the tensor\n",
        "print(u.grad_fn)  #gradient function used\n",
        "print(u.grad)   #gradient w.r.t. v (usually None unless .retain_grad() was called)\n",
        "print(u.is_leaf)  #checks if its a leaf node or not in computational graph\n",
        "print(u.requires_grad)  #checks if requires_grad was used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfV5OC6kLaAE",
        "outputId": "e8733099-8d38-480d-d24e-53bac1f5fd1d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.)\n",
            "None\n",
            "tensor(8.)\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(v.data)\n",
        "print(v.grad_fn)\n",
        "print(v.grad)\n",
        "print(v.is_leaf)\n",
        "print(v.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Bb192OLtbx",
        "outputId": "a6af96ab-d0a0-410e-b552-ff131f00a68e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.)\n",
            "None\n",
            "tensor(3.)\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f.data)\n",
        "print(f.grad_fn)\n",
        "print(f.grad)\n",
        "print(f.is_leaf)\n",
        "print(f.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkdmPtZQLymv",
        "outputId": "d0352c83-427b-45f2-ff76-e9e8d9c2c4ed"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(15.)\n",
            "<AddBackward0 object at 0x7b187ab6efb0>\n",
            "None\n",
            "False\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-fe500fcbc550>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(f.grad)\n"
          ]
        }
      ]
    }
  ]
}